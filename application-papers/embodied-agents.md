## Embodied Agents
Minecraftã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ã‚„å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã®ã‚ˆã†ã«ä½“ãŒã‚ã‚Šã€ç’°å¢ƒã‚’ç§»å‹•ã—ãªãŒã‚‰ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

æœªçŸ¥ã®ç’°å¢ƒã«å¯¾ã™ã‚‹é ‘å¥ã•ã‚„é•·æœŸã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚

ç·»å¯†ãªè¨ˆç”»ã€ãƒ„ãƒ¼ãƒ«ã‚„ã‚¹ã‚­ãƒ«ã®ä½œæˆã€ãƒ¡ãƒ¢ãƒªã®æ´»ç”¨ãŒé‡è¦ã«ãªã‚Šã¾ã™ã€‚
<figure style="text-align: center;">
    <img alt="" src="../assets/embodied_agent.png" width="500" />
    <figcaption style="text-align: center;">å¼•ç”¨ï¼šhttps://arxiv.org/abs/2408.03615</figcaption>
</figure>

#### Papers
* âš–ï¸ [Aug 2020] **"ALFWorld: Aligning Text and Embodied Environments for Interactive Learning"** [[paper](https://arxiv.org/abs/2010.03768)]
* [Jun 2022] **"Minedojo: Building open-ended embodied agents with internet-scale knowledge"** [[paper](https://arxiv.org/abs/2206.08853)]
* [Feb 2023] **"Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents"** [[paper](https://arxiv.org/abs/2302.01560)]
* [May 2023] **"Voyager: An open-ended embodied agent with large language models"** [[paper](https://arxiv.org/abs/2305.16291)]
* [May 2023] **"Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"** [[paper](https://arxiv.org/abs/2305.17144)]
* [Jun 2023] **"STEVE-1: A Generative Model for Text-to-Behavior in Minecraft"** [[paper](https://arxiv.org/abs/2306.00937)]
* [Jul 2023] **"Building Cooperative Embodied Agents Modularly with Large Language Models"** [[paper](https://arxiv.org/abs/2307.02485)]
* [Oct 2023] **"Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"** [[paper](https://arxiv.org/abs/2310.13255)]
* [Nov 2023] **"JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models"** [[paper](https://arxiv.org/abs/2311.05997)]
* [Nov 2023] **"An Embodied Generalist Agent in 3D World"** [[paper](https://arxiv.org/abs/2311.12871)]
* [Dec 2023] **"Mp5: A multi-modal open-ended embodied system in minecraft via active perception"** [[paper](https://arxiv.org/abs/2312.07472)]
* âš–ï¸ [Dec 2023] **"EgoPlan-Bench: Benchmarking Multimodal Large Language Models for Human-Level Planning"** [[paper](https://arxiv.org/abs/2312.06722)]
* ğŸ“– [Jan 2024] **"Agent AI: Surveying the Horizons of Multimodal Interaction"** [[paper](https://arxiv.org/abs/2401.03568)]
* [Feb 2024] **"S-Agents: Self-Organizing Agents in Open-Ended Environments"** [[paper](https://arxiv.org/abs/2402.04578)]
* [Feb 2024] **"Large Language Models as Minecraft Agents"** [[paper](https://arxiv.org/abs/2402.08392)]
* ğŸ“– [Feb 2024] **"A call for embodied AI"** [[paper](https://arxiv.org/abs/2402.03824)]
* ğŸ“– [Feb 2024] **"An Interactive Agent Foundation Model"** [[paper](https://arxiv.org/abs/2402.05929)]
* [Mar 2024] **"Scaling Instructable Agents Across Many Simulated Worlds"** [[paper](https://arxiv.org/abs/2404.10179)]
* [Mar 2024] **"Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation"** [[paper](https://arxiv.org/abs/2403.08282)]
* [Mar 2024] **"EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents"** [[paper](https://arxiv.org/abs/2403.12014)]
* ğŸ“– [Mar 2024] **"A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges"** [[paper](https://arxiv.org/abs/2403.10249)]
* ğŸ“– [Apr 2024]**"A Survey on Large Language Model-Based Game Agents"** [[paper](https://arxiv.org/abs/2404.02039)]
* ğŸ“– [Jun 2024] **"A Survey on Vision-Language-Action Models for Embodied AI"** [[paper](https://arxiv.org/abs/2405.14093)]
* [Jul 2024] **"ODYSSEY: Empowering Agents with Open-World Skills"** [[paper](https://arxiv.org/abs/2407.15325)]
* [Jul 2024] **"GRUtopia: Dream General Robots in a City at Scale"** [[paper](https://arxiv.org/abs/2407.10943)]
* ğŸ”¥ ğŸ“– [Jul 2024]  **"Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models"** [[paper](https://arxiv.org/abs/2407.07035)]
* [Aug 2024] **"Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks"** [[paper](https://arxiv.org/abs/2408.03615)]
* [Aug 2024] **"EmBARDiment: an Embodied AI Agent for Productivity in XR"** [[paper](https://arxiv.org/abs/2408.08158)]
* [Aug 2024] **"EAIRiskBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents"** [[paper](https://arxiv.org/abs/2408.04449)]
* [Oct 2024] **"Mars: Situated Inductive Reasoning in an Open-World Environment"** [[paper](https://arxiv.org/abs/2410.08126)]
* [Oct 2024] **"MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents"** [[paper](https://arxiv.org/abs/2410.03450)]
* âš–ï¸ [Oct 2024] **"PARTNR: A Benchmark for Planning and Reasoning in Embodied Multi-agent Tasks"** [[paper](https://arxiv.org/abs/2411.00081)]
* [Nov 2024] **"Mr.Steve:Â Instruction-FollowingÂ AgentsÂ inÂ MinecraftÂ withÂ What-Where-WhenÂ Memory"** [[paper](https://arxiv.org/abs/2411.06736)]
* [Nov 2024] **"CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation"** [[paper](https://arxiv.org/abs/2411.04679v1)]
* [Nov 2024] **"MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Collaborative Learning"** [[paper](https://arxiv.org/abs/2411.12977)]
* âš–ï¸ [Nov 2024] **"BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games"** [[paper](https://arxiv.org/abs/2411.13543)]
* [Dec 2024] **"Navigation World Models"** [[paper](https://arxiv.org/abs/2412.03572)]
* [Dec 2024] **"From Multimodal LLMs to Generalist Embodied Agents: Methods and Lessons"** [[paper](https://arxiv.org/abs/2412.08442)]
* âš–ï¸ [Dec 2024] **"Agent-SafetyBench: Evaluating the Safety of LLM Agents"** [[paper](https://arxiv.org/abs/2412.14470)]