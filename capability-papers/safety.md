## Safety
These papers discuss the safety and risks of agents.
#### Papers
* ‚öñÔ∏è [Jan 2024] **"R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"** [[paper](https://arxiv.org/abs/2401.10019)]
* [Feb 2024] **"TrustAgent: Towards Safe and Trustworthy LLM-based Agents"** [[paper](https://arxiv.org/abs/2402.01586)]
* [Feb 2024] **"Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast"** [[paper](https://arxiv.org/abs/2402.08567)]
* [Feb 2024] **"Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents"** [[paper](https://arxiv.org/abs/2402.11208)]
* [Apr 2024] **"GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications"** [[paper](https://arxiv.org/abs/2404.06921)]
* [Apr 2024] **"The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions"** [[paper](https://arxiv.org/abs/2404.13208)]
* [Apr 2024] **"GPT in Sheep's Clothing: The Risk of Customized GPTs"** [[paper](https://arxiv.org/abs/2401.09075)]
* [Apr 2024] **"Foundational Challenges in Assuring Alignment and Safety of Large Language Models"** [[paper](https://arxiv.org/abs/2404.09932)]
* üìñ [May 2024] **"The Ethics of Advanced AI Assistants"** [[paper](https://arxiv.org/abs/2404.16244)]
* [May 2024] **"AirGapAgent: Protecting Privacy-Conscious Conversational Agents"** [[paper](https://arxiv.org/abs/2405.05175)]
* [May 2024] **"Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems"** [[paper](https://arxiv.org/abs/2405.06624)]
* [May 2024] **"A Mechanism-Based Approach to Mitigating Harms from Persuasive Generative AI"** [[paper](https://arxiv.org/abs/2404.15058)]
* [Jun 2024] **"MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate"** [[paper](https://arxiv.org/abs/2406.14711)]
* [Jun 2024] **"GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning"** [[paper](https://arxiv.org/abs/2406.09187)]
* [Jul 2024] **"AGENTPOISON: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases"** [[paper](https://arxiv.org/abs/2407.12784)]
* [Aug 2024] **"ATHENA: Safe Autonomous Agents with Verbal Contrastive Learning"** [[paper](https://arxiv.org/abs/2408.11021)]
* üìñ [Aug 2024] **"The Emerged Security and Privacy of LLM Agent: A Survey with Case Studies"** [[paper](https://arxiv.org/abs/2407.19354)]
* üìñ [Aug 2024] **"Know Your Limits: A Survey of Abstention in Large Language Models"** [[paper](https://arxiv.org/abs/2407.18418v2)]
* ‚öñÔ∏è [Aug 2024] **"EAIRiskBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents"** [[paper](https://arxiv.org/abs/2408.04449)]
* [Sep 2024] **"Safeguarding AI Agents: Developing and Analyzing Safety Architectures"** [[paper](https://arxiv.org/abs/2409.03793)]
* [Oct 2024] **"Multimodal Situational Safety"** [[paper](https://arxiv.org/abs/2410.06172)]
* [Oct 2024] **"HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions"** [[paper](https://arxiv.org/abs/2409.16427)]
* ‚öñÔ∏è [Oct 2024] **"ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents"** [[paper](https://arxiv.org/abs/2410.06703)]
* ‚öñÔ∏è [Oct 2024] **"AutoPenBench: Benchmarking Generative Agents for Penetration Testing"** [[paper](https://arxiv.org/abs/2410.03225)]
* ‚öñÔ∏è [Oct 2024] **"AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents"** [[paper](https://arxiv.org/abs/2410.09024)]
* ‚öñÔ∏è [Oct 2024] **"Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents"** [[paper](https://arxiv.org/abs/2410.02644)]
* üìñ [Nov 2024] **"World Models: The Safety Perspective"** [[paper](https://arxiv.org/abs/2411.07690)]
* üî• üìñ [Nov 2024] **"Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents"** [[paper](https://arxiv.org/abs/2411.09523)]
* [Nov 2024] **"Attacking Vision-Language Computer Agents via Pop-ups"** [[paper](https://arxiv.org/abs/2411.02391)]
* ‚öñÔ∏è [Dec 2024] **"Agent-SafetyBench: Evaluating the Safety of LLM Agents"** [[paper](https://arxiv.org/abs/2412.14470)]
* [Dec 2024] **"Towards Action Hijacking of Large Language Model-based Agent"** [[ppaer](https://arxiv.org/abs/2412.10807)]
* ‚öñÔ∏è [Dec 2024] **"SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents"** [[ppaer](https://arxiv.org/abs/2412.13178)]
* [Jan 2025] **"Context is Key for Agent Security"** [[paper](https://arxiv.org/abs/2501.17070)]
* [Feb 2025] **"Safety is Essential for Responsible Open-Ended Systems"** [[paper](https://arxiv.org/abs/2502.04512)]
* [Mar 2025] **"A Practical Memory Injection Attack against LLM Agents"** [[paper](https://arxiv.org/abs/2503.03704)]
* üìñ [Mar 2025] **"A Survey on Trustworthy LLM Agents: Threats and Countermeasures"** [[paper](https://arxiv.org/abs/2503.09648)]
* [Apr 2025] **"How to evaluate control measures for LLM agents? A trajectory from today to superintelligence"** [[paper](https://arxiv.org/abs/2504.05259)]
* [Jun 2025] **"Sample, Predict, then Proceed:Self-Verification Sampling for Tool Use of LLMs"** [[paper](https://arxiv.org/abs/2506.02918)]
* [Jun 2025] **"TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems"** [[paper](http://arxiv.org/abs/2506.04133)]
* [Jun 2025] **"AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents"** [[paper](https://arxiv.org/abs/2506.04018)]
* [Jun 2025] **"Helpful Agent Meets Deceptive Judge: Understanding Vulnerabilities in Agentic Workflows"** [[paper](https://arxiv.org/abs/2506.03332)]
* ‚öñÔ∏è [Jun 2025] **"DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments"** [[paper](https://arxiv.org/abs/2506.00739)]
* [Jun 2025] **"AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents"** [[paper](https://arxiv.org/abs/2506.00641)]
* ‚öñÔ∏è [Jun 2025] **"SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents"** [[paper](https://www.arxiv.org/abs/2506.15740)]
* üìñ [Jun 2025] **"From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows"** [[paper](https://arxiv.org/abs/2506.23260)]
* üìñ [Jun 2025] **"A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents"** [[paper](https://arxiv.org/abs/2506.23844)]
* [Jul 2025] **"GAF-Guard: An Agentic Framework for Risk Management and Governance in Large Language Models"** [[paper](https://arxiv.org/abs/2507.02986)]
* [Jul 2025] **"Towards Enforcing Company Policy Adherence in Agentic Workflows"** [[paper](https://arxiv.org/abs/2507.16459)]
* üî• [Jul 2025] **"Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition"** [[paper](https://arxiv.org/abs/2507.20526)]
* üìñ [Jul 2025] **"Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report"** [[paper](https://arxiv.org/abs/2507.16534)]
* [Aug 2025] **"Search-Time Data Contamination"** [[paper](https://www.arxiv.org/abs/2508.13180)]
* [Aug 2025] **"Reliable Weak-to-Strong Monitoring of LLM Agents"** [[paper](https://arxiv.org/abs/2508.19461)]
* [Sep 2025] **"Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios"** [[paper](https://www.arxiv.org/abs/2509.04403)]
* üìñ [Sep 2025] **"LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions"** [[paper](https://arxiv.org/abs/2509.18970)]