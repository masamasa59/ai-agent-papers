## Self-Evolution手法のトレンドと課題（2026年1月）

### 手法の根幹とトレンド（3ヶ月前と比較）
2025年10月時点のSelf-Evolutionは、エージェントのワークフロー生成や、経験に基づくライフサイクルの構築、ツールのオーケストレーションといった「システムの設計・構成」の自動化が中心であった。しかし、2026年1月に入り、トレンドはさらに踏み込んだ「推論時・実行時（Runtime）の動的変容」へと完全にシフトしている。

第一に、静的なワークフロー設計から、実行時の動的ルーティングへの進化である。事前に定義された固定的なフローではなく、入力されたクエリの性質に応じて最適なリソース（モデルやツール）を自律配分する手法が一般化した。第二に、エピソードメモリを単なる情報の検索ソースとしてではなく、実行時の強化学習データとして即座に活用し、行動ポリシーをリアルタイムで洗練させる「オンライン自己進化」の台頭。第三に、既存ツールの呼び出しに留まらず、推論の過程で必要に応じて新たなツールを自作・増強する能力の獲得。第四に、単なる試行錯誤の反省を超え、自身の思考プロセスを客観視して抽象化された教訓を得る「メタ認知的な学習」の導入である。総じて、3ヶ月前よりもシステムの「固定的構造」からの脱却が進み、不確実な環境下でその場その場で自身を再定義する能力が重視されている。

### 課題傾向
進化の自律性が高まる一方で、以下の3つの深刻な課題が浮き彫りになっている。

1. **自己進化の忠実性（Faithfulness）の欠如**: エージェントの自己評価と実体性能の乖離、および誤った自己修正による性能劣化（退化）のリスクをいかに定量的・客観的に監視し、安全な進化パスを確保するかという信頼性が問われている。
2. **長期の一貫性と安定性（Consistency）**: 長期間にわたる複雑なタスクにおける自己進化プロセスでのメモリ汚染や、進化ロジックの暴走を防ぎつつ、一貫した目的意識と性能を維持するための制御メカニズムの構築。
3. **ゼロスタート環境での適応コスト**: 特定のドメインへの事前適合なしの状態から、実環境との相互作用のみを通じて、いかに迅速かつ効率的に開かれたタスク（Open-ended Tasks）に対して自己進化を開始できるかという初期学習の収束速度。

### 論文紹介

[JENIUS AGENT](https://arxiv.org/abs/2601.01857)
実世界の複雑なシナリオにおいて、エージェントが経験を通じて自律的に精度を向上させるフレームワーク。過去のタスク実行から得られたフィードバックや中間結果を詳細に分析し、推論パスの誤りを特定して修正する「経験駆動型最適化」が核心である。特定のデータセットに過学習することなく、未経験の状況下でも過去の類似失敗から学んだ「教訓」を適用することで、動的な環境変化に対する適応力を大幅に高めている。プロンプトの微調整にとどまらず、思考のロジック自体を環境に合わせて再構成する汎用的な自己改善メカズムを提案している。

[EvoRoute](https://arxiv.org/abs/2601.02695)
複数のLLMやツールが混在するエージェントシステムにおいて、入力されたクエリごとに最適なリソースを選択・配分するルーティング戦略を自律的に進化させる手法。過去の処理成否や消費コスト、実行時間を構造的な「ルーティング経験」として蓄積し、強化学習を用いて経路選択肢を動的に洗練する。これにより、単純なルータよりも高度に、環境やタスクの難易度に応じた最適な推論経路をエージェント自身が発見・調整できるようになる。システムの基本性能を維持しながら、実行効率を自己改善するメカズムとして機能する。

[MEMRL](https://arxiv.org/abs/2601.03192)
エピソードメモリを強化学習の動的なデータソースとして活用し、実行時（Runtime）にエージェントを自己改善させるフレームワーク。従来のRAGが情報の受動的な検索に留まるのに対し、本手法では過去の成功・失敗体験を即座に行動方針の修正に反映させるオンライン学習機能を備える。エピソードは現実の相互作用を通じて得た報酬信号に基づき、自身の行動ポリシーをリアルタイムで進化させる。情報の「記録」ではなく、記憶から直接「スキル」を抽出し、未知の環境下での迅速な適応と生存能力を高めることに特化している。

[PACEvolve](https://arxiv.org/abs/2601.10657v1)
進捗認識型（Progress-Aware）の一貫した進化を実現するためのフレームワーク。長期間にわたる複雑なタスクにおいて、過去の試行錯誤によるコンテキスト汚染を防ぎつつ、現在の進捗状況に合わせて最適な自己進化戦略を動的に選択する。階層的なコンテキスト管理とバックトラッキング手法を組み合わせることで、探索と活用のバランスを高度に最適化している。メモリを単なるログではなく、探索を導く「進捗マップ」として扱い、自己改善プロセスが一貫性を失い暴走することを防ぐ制御メカズムが手法の根幹である。

[Beyond Static Tools](https://arxiv.org/abs/2601.07641v1)
科学的推論などの高度な専門知識を要するタスクにおいて、あらかじめ定義された固定的なツール群に縛られず、推論時に動的にツールを生成・修正・進化させる手法。既存のツールでは解決できない問題に直面した際、エージェントがPythonスクリプト等で新たな「メタツール」を自作し、それを自身のスキルライブラリに追加・洗練していく。静的なAPIの組み合わせを超え、タスクの要求に合わせて自分自身の「手足」を再定義・増強することで、従来のAIエージェントの限界を超える柔軟な問題解決能力を実現している。

[WISE-Flow](https://arxiv.org/abs/2601.08158v1)
対話サービスエージェント向けに、ワークフローに基づく構造的な「経験」を蓄積し、それをもとにエージェントの振る舞いを自己進化させる手法。従来の平坦なログではなく、特定のビジネス目標や対話フローのどの段階で何が起き、成功したかというコンテキストを付与した形式で経験を管理する。この構造化された経験をメタプロンプトや強化学習の入力として用いることで、複雑な顧客ニーズや変化するサービス規定に対し、エージェントが人間による再指示なしでサービス品質を自律的に向上させることを可能にする。

[To Retrieve or To Think?](https://arxiv.org/abs/2601.08747v2)
コンテキストの進化過程における「情報の検索」と「能動的な思考」のバランスをエージェントが自律的に決定するアプローチ。単に情報を外部から取得するだけでなく、取得した断片から新たな知識を推論・合成し、その結果を再びコンテキストに組み込むことで、情報の質を段階的に高めていく。固定されたRAGプロセスを超え、状況に応じて「今はさらに調べるべきか、それとも既存の情報から結論を導き出すべきか」というメタ判断を行いながらコンテキストを自己組織化する点に新規性がある。

[Controlled Self-Evolution](https://arxiv.org/abs/2601.07348v4)
アルゴリズムのコード最適化において、安定性と信頼性を保ちながら極限まで性能を追求するための制御された自己進化手法。エージェントがコードを書き換える際、形式的な検証と実行プロファイルによる定量的評価を密に連携させ、バグの混入を防ぎつつ実行速度やメモリ効率を向上させる。ランダムな探索ではなく、不変条件を維持しつつ進化の方向性を論理的に導くことで、高性能かつ実用的なコードへの自動進化を実現する。特に数値計算やシステム最適化の領域で高い効果を発揮する。

[Learn Like Humans](https://arxiv.org/abs/2601.11974v1)
人間特有のメタ認知的な省察（Reflection）プロセスをモデル化し、効率的な自己改善を実現する手法。自身の思考ステップや結論を客観的な視点から評価し、失敗の根本原因や成功の鍵となる要因を抽象化された「教訓」として抽出する。この省察結果をメタ学習に組み込むことで、大量の試行錯誤を必要とせず、一度の失敗からも深く学び、将来の類似課題に活かすことができる。情報の単純な蓄積ではなく、認知プロセス自体の高度化を通じた「賢い学び方」の獲得が核心である。

[From Storage to Experience](https://www.preprints.org/manuscript/202601.0618)
エージェントのメモリメカニズムが、単なるデータの格納庫（Storage）から、自律的な進化を支える「経験（Experience）」へと変遷した動向を体系的にまとめたサーベイ。初期のプロンプト拡張から、近年の動的ワークフローやエピソード駆動型学習への移行を整理。単なる情報の断片を保持するのではなく、状況に応じた手続きや推論のパターンを構造化された形式で再利用することが、次世代の自己進化エージェントにおける核心的な技術課題であると位置づけている。理論的背景と将来の展望を包括的に提示。

[Inference-Time Scaling](https://arxiv.org/abs/2601.15808)
推論時（Inference-Time）に検証プロセスをスケールさせることで、事後的な自己進化を実現する手法。タスク実行の各段階で、設定された複数のルブリック（評価基準）に基づき、エージェントが自ら検証と修正を繰り返す。計算資源を推論時の思考の深さに投じることで、モデルの事前学習時の限界を超えた高度な調査・分析能力を引き出す。検証履歴を自身の重みやポリシーに還元するフィードバックループを備えており、使えば使うほど特定の高度な推論タスクに特化して性能が向上する。

[Optimizing Agentic Workflows](https://arxiv.org/abs/2601.22037v1)
「メタツール（ツールを管理・最適化するツール）」を用いて、エージェント間の連携経路や実行順序などのワークフローを自律的に進化させる手法。個々のタスクを解くエージェントとは別に、システム全体の「設計者」としての役割を持つメタエージェントを配置し、実行ログを分析してボトルネックを解消する新しい構成を提案する。タスクの性質に応じて最適な「チーム構成」を動的に組み替え、進化させることで、単一の静的なワークフローでは対応できない複雑なリアルタイム課題の解決を目指す。

[Yunjue Agent Tech Report](https://arxiv.org/abs/2601.18226)
事前定義やドメイン知識がほぼゼロの状態（Zero-Start）から、実環境との相互作用のみを通じてその場（In-Situ）で自己進化を開始するシステムの技術報告。開かれた課題（Open-ended Tasks）に対し、エージェントが自律的に目標を細分化し、試行錯誤を通じて有効なツールセットや計画手順を自ら発見・構築していくプロセスを詳細に記述。完全な再現性を維持しつつ、ゼロからの自動化と能力拡張が可能であることを実証しており、エージェント構築の省力化と非定形タスクへの適応において重要な知見を提供。

[Large Language Model Agents Are Not Always Faithful Self-Evolvers](https://arxiv.org/abs/2601.22436)
LLMエージェントが自己改善を試みる際、必ずしも実体性能の向上に繋がるとは限らない「不忠実性（Faithfulness）」の問題を鋭く指摘した論文。エージェントが自身の誤りを正しく認識できなかったり、表面的な修正で「改善した」と誤認したりすることで、結果的にシステムが劣化するリスクを実験的に示した。自己進化の自律性を妄信するのではなく、進化のプロセスをいかに定量的かつ客観的に監視し、安全な進化パスを確保するかという信頼性向上のための課題を整理している。

[Position: Agentic Evolution](https://arxiv.org/abs/2602.00359)
「エージェントとしての進化こそがLLMの能力を真に拡張する道である」と提唱するポジションペーパー。静的なテキストコーパスによる事前学習の限界を指摘し、環境との動的な相互作用、自律的なツール獲得、そして他者との経験共有こそが、AIをより高度な知性へと導く核であると主張。単なる予測精度の向上ではなく、能動的に世界に働きかけ、自らを定義し直す「プロセスとしての知能」の重要性を説いており、今後の研究の方向性を指し示す野心的な提言となっている。